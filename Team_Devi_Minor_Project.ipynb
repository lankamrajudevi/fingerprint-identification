{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JozsQQ-oUT0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8488b95a-5b3a-424c-e416-1f514f2823e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, target_size=(128, 128)):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        print(f\"Error: Unable to load image file '{image_path}'.\")\n",
        "        return None\n",
        "    image = cv2.equalizeHist(image)\n",
        "    image = cv2.resize(image, target_size)\n",
        "    return image"
      ],
      "metadata": {
        "id": "n-tU2Si7V2dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_gabor_filters(image):\n",
        "    kernels = []\n",
        "    for theta in range(4):\n",
        "        theta = theta / 4. * np.pi\n",
        "        for sigma in (1, 3):\n",
        "            for frequency in (0.05, 0.25):\n",
        "                kernel = cv2.getGaborKernel((21, 21), sigma, theta, frequency, 0.5, 0, ktype=cv2.CV_32F)\n",
        "                filtered_image = cv2.filter2D(image, cv2.CV_32F, kernel)\n",
        "                kernels.append(filtered_image)\n",
        "    return np.array(kernels)"
      ],
      "metadata": {
        "id": "i0FN8uZeV6I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn(input_shape):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "QeHcXTZ_V9Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset_path, target_size=(128, 128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {}\n",
        "    for root, _, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                label_folder = os.path.basename(root)\n",
        "                if label_folder not in label_map:\n",
        "                    label_map[label_folder] = len(label_map)\n",
        "                label = label_map[label_folder]\n",
        "                image = preprocess_image(image_path, target_size)\n",
        "                if image is not None:\n",
        "                    images.append(image)\n",
        "                    labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "KLrWth_QWFsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/dataset_FVC2000_DB4_B/dataset\"\n",
        "images, labels = load_dataset(dataset_path)"
      ],
      "metadata": {
        "id": "y6hPCoxKWGsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gabor_features = []\n",
        "for img in images:\n",
        "    filtered_images = apply_gabor_filters(img)\n",
        "    gabor_features.append(filtered_images)\n",
        "\n",
        "gabor_features = np.array(gabor_features)"
      ],
      "metadata": {
        "id": "M6r1Z1zrWMIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = gabor_features.reshape(len(gabor_features), gabor_features.shape[2], gabor_features.shape[3], gabor_features.shape[1])\n",
        "y = labels\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train the model\n",
        "cnn_model = build_cnn((X_train.shape[1], X_train.shape[2], X_train.shape[3]))\n",
        "cnn_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "cnn_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuGZXLTUWUt2",
        "outputId": "9189e571-9fce-4996-fec2-85502fd98b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.8257 - loss: 5167.8228 - val_accuracy: 0.9818 - val_loss: 5339.1909\n",
            "Epoch 2/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.9430 - loss: 5054.5225 - val_accuracy: 0.9818 - val_loss: 2880.7478\n",
            "Epoch 3/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9933 - loss: 1126.1949 - val_accuracy: 0.9818 - val_loss: 792.3975\n",
            "Epoch 4/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.9518 - loss: 628.2405 - val_accuracy: 0.9818 - val_loss: 882.9822\n",
            "Epoch 5/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9839 - loss: 647.7166 - val_accuracy: 0.5091 - val_loss: 1002.1494\n",
            "Epoch 6/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9032 - loss: 335.2581 - val_accuracy: 0.9818 - val_loss: 544.5643\n",
            "Epoch 7/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9691 - loss: 320.3873 - val_accuracy: 0.9818 - val_loss: 640.6447\n",
            "Epoch 8/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.9884 - loss: 361.2068 - val_accuracy: 0.9818 - val_loss: 238.1741\n",
            "Epoch 9/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9824 - loss: 57.4251 - val_accuracy: 0.9818 - val_loss: 258.3135\n",
            "Epoch 10/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9959 - loss: 29.3107 - val_accuracy: 0.9818 - val_loss: 61.5277\n",
            "Epoch 11/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9742 - loss: 12.7677 - val_accuracy: 0.9818 - val_loss: 37.6740\n",
            "Epoch 12/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9926 - loss: 6.0910 - val_accuracy: 0.9697 - val_loss: 30.8223\n",
            "Epoch 13/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9922 - loss: 2.1866 - val_accuracy: 0.9818 - val_loss: 52.4212\n",
            "Epoch 14/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9933 - loss: 3.1886 - val_accuracy: 0.9818 - val_loss: 47.0213\n",
            "Epoch 15/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9915 - loss: 4.7023 - val_accuracy: 0.9636 - val_loss: 22.3384\n",
            "Epoch 16/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.9946 - loss: 2.6618 - val_accuracy: 0.9636 - val_loss: 19.0411\n",
            "Epoch 17/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9883 - loss: 2.5879 - val_accuracy: 0.9636 - val_loss: 18.1206\n",
            "Epoch 18/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.9898 - loss: 3.0934 - val_accuracy: 0.9636 - val_loss: 19.9770\n",
            "Epoch 19/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.9885 - loss: 4.7338 - val_accuracy: 0.9818 - val_loss: 26.2786\n",
            "Epoch 20/20\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9958 - loss: 2.0806 - val_accuracy: 0.9818 - val_loss: 25.2611\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 0.9754 - loss: 38.2309\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25.261117935180664, 0.9818181991577148]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}